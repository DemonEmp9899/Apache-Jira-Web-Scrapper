{"issue_id": "KAFKA-12345", "project": "KAFKA", "title": "Consumer group rebalance causes duplicate processing", "description": "When a consumer group undergoes rebalancing, messages can be processed multiple times. This happens because the offset commit fails during the rebalance window, causing the consumer to restart from the last committed offset.\n\nSteps to reproduce:\n1. Start consumer group with 3 consumers\n2. Add a 4th consumer to trigger rebalance\n3. Observe duplicate processing of messages during rebalance\n\nExpected: No duplicate processing\nActual: Messages processed 2-3 times", "status": "Resolved", "priority": "Major", "issue_type": "Bug", "reporter": "John Smith", "assignee": "Jane Doe", "created_date": "2024-01-15T10:30:00.000+0000", "updated_date": "2024-01-20T14:22:00.000+0000", "resolved_date": "2024-01-20T14:22:00.000+0000", "labels": ["consumer", "rebalance", "duplicate-processing"], "components": ["consumer", "core"], "comments": [{"author": "Jane Doe", "created": "2024-01-16T09:15:00.000+0000", "body": "I've identified the root cause. The issue is in the offset commit logic. During rebalancing, we need to ensure offsets are committed before the rebalance completes."}, {"author": "John Smith", "created": "2024-01-16T11:30:00.000+0000", "body": "Makes sense. Should we add a commit during the rebalance callback?"}, {"author": "Jane Doe", "created": "2024-01-17T08:45:00.000+0000", "body": "Yes, I've implemented a fix that commits offsets in the onPartitionsRevoked callback. This ensures offsets are saved before partitions are reassigned."}, {"author": "Jane Doe", "created": "2024-01-20T14:22:00.000+0000", "body": "Fix merged. The consumer now properly commits offsets during rebalancing, preventing duplicate processing."}], "training_task": "question_answering"}
{"issue_id": "SPARK-67890", "project": "SPARK", "title": "Add support for Delta Lake time travel in Spark SQL", "description": "This PR adds support for querying Delta Lake tables at specific versions or timestamps using SQL syntax.\n\nUsers can now use:\n- SELECT * FROM table VERSION AS OF 123\n- SELECT * FROM table TIMESTAMP AS OF '2024-01-01'\n\nImplementation includes:\n- Parser changes to support new SQL syntax\n- Logical plan nodes for time travel operations\n- Physical execution with Delta Lake version resolution\n- Comprehensive test coverage\n\nPerformance impact: negligible overhead for standard queries, efficient version lookup for time travel queries.", "status": "Open", "priority": "Major", "issue_type": "New Feature", "reporter": "Alice Johnson", "assignee": "Bob Wilson", "created_date": "2024-02-01T08:00:00.000+0000", "updated_date": "2024-02-10T16:45:00.000+0000", "resolved_date": null, "labels": ["sql", "delta-lake", "time-travel"], "components": ["SQL", "Catalyst"], "comments": [{"author": "Bob Wilson", "created": "2024-02-02T10:20:00.000+0000", "body": "Started working on the parser changes. Should have initial implementation ready by end of week."}, {"author": "Charlie Brown", "created": "2024-02-05T14:30:00.000+0000", "body": "This is a great addition! Will this work with external Delta tables too?"}, {"author": "Bob Wilson", "created": "2024-02-05T15:15:00.000+0000", "body": "Yes, it works with both managed and external Delta tables. The version resolution is handled by Delta Lake itself."}], "training_task": "summarization"}
{"issue_id": "AIRFLOW-11111", "project": "AIRFLOW", "title": "DAG fails with 'NoneType' error in task execution", "description": "DAG execution fails intermittently with NoneType error. Stack trace shows error in task execution.", "status": "Open", "priority": "Critical", "issue_type": "Bug", "reporter": "David Lee", "assignee": null, "created_date": "2024-03-01T07:30:00.000+0000", "updated_date": "2024-03-01T07:30:00.000+0000", "resolved_date": null, "labels": ["task-execution", "error"], "components": ["executor"], "comments": [], "training_task": "classification"}
